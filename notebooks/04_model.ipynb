{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "febd45b6",
   "metadata": {},
   "source": [
    "# ML MODELS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546fb5e8",
   "metadata": {},
   "source": [
    "## Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "388a828b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports básicos\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Imports de sklearn\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import TimeSeriesSplit, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "\n",
    "# Configuración de visualización\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "dcb82de6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "PRIMERAS 5 FILAS DEL DATASET\n",
      "==================================================\n",
      "   Digital_sat  TV_sat  OOH_sat  promo  trend  Month  holiday_a  holiday_b  \\\n",
      "0     0.142295     0.0      0.0      0      1      1          1          0   \n",
      "1     0.296500     0.0      0.0      1      2      1          0          0   \n",
      "2     0.383901     0.0      0.0      0      3      1          0          0   \n",
      "3     0.523305     0.0      0.0      1      4      1          0          0   \n",
      "4     0.461213     0.0      0.0      0      5      2          0          0   \n",
      "\n",
      "   holiday_c     Sales        Date  \n",
      "0          0  26129335  2013-01-06  \n",
      "1          0  49275222  2013-01-13  \n",
      "2          0  34377765  2013-01-20  \n",
      "3          0  46040169  2013-01-27  \n",
      "4          0  38466029  2013-02-03  \n",
      "\n",
      "==================================================\n",
      "INFORMACIÓN DEL DATASET\n",
      "==================================================\n",
      "Filas: 135\n",
      "Columnas: 11\n",
      "\n",
      "Columnas disponibles:\n",
      "['Digital_sat', 'TV_sat', 'OOH_sat', 'promo', 'trend', 'Month', 'holiday_a', 'holiday_b', 'holiday_c', 'Sales', 'Date']\n",
      "\n",
      "==================================================\n",
      "TIPOS DE DATOS\n",
      "==================================================\n",
      "Digital_sat    float64\n",
      "TV_sat         float64\n",
      "OOH_sat        float64\n",
      "promo            int64\n",
      "trend            int64\n",
      "Month            int64\n",
      "holiday_a        int64\n",
      "holiday_b        int64\n",
      "holiday_c        int64\n",
      "Sales            int64\n",
      "Date            object\n",
      "dtype: object\n",
      "\n",
      "==================================================\n",
      "VALORES NULOS\n",
      "==================================================\n",
      "Digital_sat    0\n",
      "TV_sat         0\n",
      "OOH_sat        0\n",
      "promo          0\n",
      "trend          0\n",
      "Month          0\n",
      "holiday_a      0\n",
      "holiday_b      0\n",
      "holiday_c      0\n",
      "Sales          0\n",
      "Date           0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Cargar el dataset de saturación\n",
    "df = pd.read_csv('../data/processed/weekly_sales_saturation.csv')\n",
    "\n",
    "# Ver las primeras filas\n",
    "print(\"=\" * 50)\n",
    "print(\"PRIMERAS 5 FILAS DEL DATASET\")\n",
    "print(\"=\" * 50)\n",
    "print(df.head())\n",
    "\n",
    "# Ver información del dataset\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"INFORMACIÓN DEL DATASET\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Filas: {df.shape[0]}\")\n",
    "print(f\"Columnas: {df.shape[1]}\")\n",
    "print(f\"\\nColumnas disponibles:\\n{df.columns.tolist()}\")\n",
    "\n",
    "# Verificar tipos de datos\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"TIPOS DE DATOS\")\n",
    "print(\"=\" * 50)\n",
    "print(df.dtypes)\n",
    "\n",
    "# Verificar valores nulos\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"VALORES NULOS\")\n",
    "print(\"=\" * 50)\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7298b5f",
   "metadata": {},
   "source": [
    "### model prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e4b0dabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols= [\n",
    "    'Digital_sat',\n",
    "    'TV_sat',\n",
    "    'OOH_sat',\n",
    "    'promo',\n",
    "    'trend',\n",
    "    'Month',\n",
    "    'holiday_a'\n",
    "]\n",
    "\n",
    "X= df[feature_cols]\n",
    "y = df['Sales']\n",
    "dates= df['Date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a666dba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (135, 7)\n",
      "y shape: (135,)\n",
      "dates shape: (135,)\n"
     ]
    }
   ],
   "source": [
    "print(f\"X shape: {X.shape}\")\n",
    "print(f\"y shape: {y.shape}\")\n",
    "print(f\"dates shape: {dates.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "d9b73f50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(108, 7)\n",
      "(27, 7)\n"
     ]
    }
   ],
   "source": [
    "# Divide en orden: primero train, después test\n",
    "split_idx = int(len(X) * 0.8)\n",
    "\n",
    "X_train = X[:split_idx]   # Primeras 80% semanas\n",
    "X_test = X[split_idx:]    # Últimas 20% semanas\n",
    "y_train = y[:split_idx]\n",
    "y_test = y[split_idx:]\n",
    "dates_train = dates[:split_idx]\n",
    "dates_test = dates[split_idx:]\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "75e1e652",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0135dcb",
   "metadata": {},
   "source": [
    "### Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "019efdb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor alpha: 50\n",
      "Mejor R² (CV): 0.4248\n",
      "   param_alpha  mean_test_score  std_test_score\n",
      "0           50         0.424776        0.181724\n",
      "1          100         0.318765        0.147923\n",
      "2          200         0.196289        0.122319\n",
      "3          500         0.058580        0.098097\n",
      "4         1000        -0.009463        0.091587\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# alpha list \n",
    "param_grid = {'alpha': [50, 100, 200, 500, 1000]}\n",
    "\n",
    "# time series split \n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "# Grid search CV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator= Ridge(),\n",
    "    param_grid= param_grid,\n",
    "    cv= tscv,\n",
    "    scoring= 'r2',\n",
    "    n_jobs=1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train_scaled,y_train)\n",
    "\n",
    "# Mejor alpha encontrado\n",
    "print(f\"Mejor alpha: {grid_search.best_params_['alpha']}\")\n",
    "\n",
    "# Mejor score (R² en training con CV)\n",
    "print(f\"Mejor R² (CV): {grid_search.best_score_:.4f}\")\n",
    "\n",
    "# Ver todos los resultados\n",
    "results_df = pd.DataFrame(grid_search.cv_results_)\n",
    "print(results_df[['param_alpha', 'mean_test_score', 'std_test_score']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a17f5ffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26942304368170034\n"
     ]
    }
   ],
   "source": [
    "# Modelo final con mejor alpha\n",
    "best_model = Ridge(alpha=50)\n",
    "best_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predicciones\n",
    "y_pred_train = best_model.predict(X_train_scaled)\n",
    "y_pred_test = best_model.predict(X_test_scaled)\n",
    "\n",
    "r2 = r2_score(y_test, y_pred_test)\n",
    "print(r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c992709f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set - Primeras 10 observaciones:\n",
      "     y_real        y_pred         error\n",
      "0  50783355  4.602515e+07  4.758206e+06\n",
      "1  50548507  4.597827e+07  4.570240e+06\n",
      "2  39497832  3.631331e+07  3.184524e+06\n",
      "3  48295825  4.500307e+07  3.292750e+06\n",
      "4  39936680  3.642484e+07  3.511837e+06\n",
      "5  52123970  4.556520e+07  6.558767e+06\n",
      "6  39436926  3.575331e+07  3.683618e+06\n",
      "7  50662424  4.408906e+07  6.573364e+06\n",
      "8  39585055  3.549100e+07  4.094058e+06\n",
      "9  55923085  4.596077e+07  9.962310e+06\n",
      "\n",
      "Rango y_test: 34879894 - 55923085\n",
      "Rango y_pred_test: 34914677 - 46025149\n",
      "\n",
      "R² Training: 0.6719\n",
      "R² Test: 0.2694\n",
      "R² Baseline (media): -0.2153\n"
     ]
    }
   ],
   "source": [
    " #1. Compara predicciones vs valores reales\n",
    "print(\"Test Set - Primeras 10 observaciones:\")\n",
    "comparison = pd.DataFrame({\n",
    "    'y_real': y_test[:10].values,\n",
    "    'y_pred': y_pred_test[:10],\n",
    "    'error': y_test[:10].values - y_pred_test[:10]\n",
    "})\n",
    "print(comparison)\n",
    "\n",
    "# 2. Compara rangos\n",
    "print(f\"\\nRango y_test: {y_test.min():.0f} - {y_test.max():.0f}\")\n",
    "print(f\"Rango y_pred_test: {y_pred_test.min():.0f} - {y_pred_test.max():.0f}\")\n",
    "\n",
    "# 3. Verifica R² en training (debería ser alto)\n",
    "r2_train = r2_score(y_train, y_pred_train)\n",
    "print(f\"\\nR² Training: {r2_train:.4f}\")\n",
    "print(f\"R² Test: {r2:.4f}\")\n",
    "\n",
    "# 4. Calcula baseline (predecir solo la media)\n",
    "baseline_pred = np.full(len(y_test), y_train.mean())\n",
    "r2_baseline = r2_score(y_test, baseline_pred)\n",
    "print(f\"R² Baseline (media): {r2_baseline:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "87039865",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor alpha: 10\n",
      "R² CV: 0.3133\n",
      "R² Test: -0.1239\n"
     ]
    }
   ],
   "source": [
    "# 1. Reducir features - quitar las holidays menos frecuentes\n",
    "feature_cols_simple = [\n",
    "    'Digital_sat',\n",
    "    'TV_sat', \n",
    "    'OOH_sat',\n",
    "    'promo',\n",
    "    'trend',\n",
    "    'Month'\n",
    "]\n",
    "\n",
    "# 2. Recrear X con menos features\n",
    "X_simple = df[feature_cols_simple]\n",
    "\n",
    "# 3. Hacer el mismo split temporal\n",
    "split_idx = int(len(X_simple) * 0.8)\n",
    "X_train_simple = X_simple[:split_idx]\n",
    "X_test_simple = X_simple[split_idx:]\n",
    "\n",
    "# 4. SIN SCALING (las features ya están normalizadas)\n",
    "# Digital_sat, TV_sat, OOH_sat ya están en [0,1]\n",
    "# No necesitas StandardScaler para Ridge con features ya normalizadas\n",
    "\n",
    "# 5. GridSearch con alphas más altos\n",
    "param_grid = {'alpha': [10, 50, 100, 200, 500]}\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    Ridge(),\n",
    "    param_grid,\n",
    "    cv=tscv,\n",
    "    scoring='r2'\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train_simple, y_train)\n",
    "\n",
    "# 6. Evaluar\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred_test = best_model.predict(X_test_simple)\n",
    "\n",
    "print(f\"Mejor alpha: {grid_search.best_params_['alpha']}\")\n",
    "print(f\"R² CV: {grid_search.best_score_:.4f}\")\n",
    "print(f\"R² Test: {r2_score(y_test, y_pred_test):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "3bb8f800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "COMPARACIÓN TRAIN vs TEST\n",
      "============================================================\n",
      "\n",
      "Sales - Train:\n",
      "  Media: 42,888,583\n",
      "  Std: 8,020,733\n",
      "  Min: 26,129,335\n",
      "  Max: 75,371,329\n",
      "\n",
      "Sales - Test:\n",
      "  Media: 45,970,878\n",
      "  Std: 6,769,637\n",
      "  Min: 34,879,894\n",
      "  Max: 55,923,085\n",
      "\n",
      "============================================================\n",
      "FEATURES - Comparación de medias\n",
      "============================================================\n",
      "Digital_sat     | Train:   0.4615 | Test:   0.4754 | Diff:   +3.0%\n",
      "TV_sat          | Train:   0.2781 | Test:   0.0885 | Diff:  -68.2%\n",
      "OOH_sat         | Train:   0.3046 | Test:   0.0000 | Diff: -100.0%\n",
      "promo           | Train:   0.5278 | Test:   0.5556 | Diff:   +5.3%\n",
      "trend           | Train:  54.5000 | Test: 122.0000 | Diff: +123.9%\n",
      "Month           | Train:   6.3519 | Test:   4.5926 | Diff:  -27.7%\n",
      "\n",
      "============================================================\n",
      "PERÍODO DEL TEST SET\n",
      "============================================================\n",
      "Train: 2013-01-06 a 2015-01-25\n",
      "Test:  2015-02-01 a 2015-08-02\n"
     ]
    }
   ],
   "source": [
    "# Analicemos las diferencias entre train y test\n",
    "print(\"=\" * 60)\n",
    "print(\"COMPARACIÓN TRAIN vs TEST\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# 1. Estadísticas básicas\n",
    "print(\"\\nSales - Train:\")\n",
    "print(f\"  Media: {y_train.mean():,.0f}\")\n",
    "print(f\"  Std: {y_train.std():,.0f}\")\n",
    "print(f\"  Min: {y_train.min():,.0f}\")\n",
    "print(f\"  Max: {y_train.max():,.0f}\")\n",
    "\n",
    "print(\"\\nSales - Test:\")\n",
    "print(f\"  Media: {y_test.mean():,.0f}\")\n",
    "print(f\"  Std: {y_test.std():,.0f}\")\n",
    "print(f\"  Min: {y_test.min():,.0f}\")\n",
    "print(f\"  Max: {y_test.max():,.0f}\")\n",
    "\n",
    "# 2. Distribución de features clave\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"FEATURES - Comparación de medias\")\n",
    "print(\"=\" * 60)\n",
    "for col in feature_cols_simple:\n",
    "    train_mean = X_train_simple[col].mean()\n",
    "    test_mean = X_test_simple[col].mean()\n",
    "    diff_pct = ((test_mean - train_mean) / train_mean * 100) if train_mean != 0 else 0\n",
    "    print(f\"{col:15} | Train: {train_mean:8.4f} | Test: {test_mean:8.4f} | Diff: {diff_pct:+6.1f}%\")\n",
    "\n",
    "# 3. Ver las fechas del test set\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"PERÍODO DEL TEST SET\")\n",
    "print(\"=\" * 60)\n",
    "dates_train = dates[:split_idx]\n",
    "dates_test = dates[split_idx:]\n",
    "print(f\"Train: {dates_train.iloc[0]} a {dates_train.iloc[-1]}\")\n",
    "print(f\"Test:  {dates_test.iloc[0]} a {dates_test.iloc[-1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834219c1",
   "metadata": {},
   "source": [
    "revisar m,i nb 01, para ver por que en tv y ooh solo puse 3 spends?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "heineken_mmm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
